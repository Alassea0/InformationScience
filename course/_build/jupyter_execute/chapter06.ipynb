{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6: Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/tablet.jpg)\n",
    "\n",
    "[Salamis tablet](https://en.wikipedia.org/wiki/Salamis_Tablet)\n",
    "\n",
    "Credit: __[Wikimedia Commons](https://en.wikipedia.org/wiki/Salamis_Tablet#/media/File:Salaminische_Tafel_Salamis_Tablet_nach_Wilhelm_Kubitschek_Numismatische_Zeitschrift_Bd_31_Wien_1899_p._394_ff.jpg)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching\n",
    "\n",
    "Very simply said, working with information often boils down to \"searching stuff\". Whether it be metadata stored in databases (e.g. searching a library catalogue), text stored in documents (e.g. a full-text search-engine for a website) or even multimedia information retrieval.\n",
    "\n",
    "Searching and search optimization are a vast area of computer science distinct type of computational problem. For instance, Donald Knuth's monumental *The Art of Computer Programming\" devotes an entire volume (3) to \"Sorting and Searching\". This means that we will only be able to briefly touch on the topic and, as always, from a very practical point of view.\n",
    "\n",
    "At face value searching might seem easy. Let's look at finding a substring in a string. In Python, for instance, offers several ways to check for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Found!\n",
      "Found!\n"
     ]
    }
   ],
   "source": [
    "my_string = \"Hello world, this is me\"\n",
    "my_search = \"me\"\n",
    "# one way\n",
    "if my_search in my_string:\n",
    "    print(\"Found!\")\n",
    "else:\n",
    "    print(\"Not found\")\n",
    "# another way\n",
    "if my_string.find(my_search) != -1:\n",
    "    print(\"Found!\")\n",
    "else:\n",
    "    print(\"Not found!\")\n",
    "# third way\n",
    "from re import search\n",
    "if search(my_search, my_string):\n",
    "    print(\"Found!\")\n",
    "else:\n",
    "    print(\"Not found!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, search operations can soon become complicated and especially time-consuming. One crucial issue is the quantity of data we need to search. The above example could afford to use a string method to look for a literal string, but obviously this is not realistic when you are searching for text millions of books (e.g. [Google Books contains >40.000.000 books](https://en.wikipedia.org/wiki/Google_Books)), or searching in huge metadata containers (e.g. [Spotify contains >50.000.000 songs](https://www.businessofapps.com/data/spotify-statistics/#:~:text=Source%3A%20Goodwater%20Capital-,Spotify%20Content%20Statistics,the%20largest%20music%20library%20available.))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing\n",
    "\n",
    "One way to deal with his issue is indexing. Simply said, an index is a data structure that improves the speed of data retrieval operations at the cost of additional writes and storage space to maintain the index data structure. \n",
    "\n",
    "Consider the following example. Let's say we have a large list of book titles and want to search them on a specific term.\n",
    "\n",
    "Let's first use SQL and the STCV database from chapter 04 to make such a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26153 titles\n",
      "100 = Den mensch van smerten, oft Jesus Christus lydende ende stervende gedurigh voor de menschen\n",
      "101 = L'homme de douleurs\n",
      "102 = Ghewichtighe waerschouwinge voor de jonghmans, in het ghene raeckt hunne besondere plicht om christelijck te leven\n",
      "103 = Gheestelycke middelen voor de suyverheydt en remedien teghen de bekoringhen\n",
      "104 = Den gheestelijcken schildt aller katholiicken\n",
      "105 = Den gheestelycken schildt aller katholycken\n",
      "106 = Vlaemsch recht dat is Costumen ende wetten [...] van Vlaenderen\n",
      "107 = Vlaems recht dat is Costvmen ende wetten [...] van Vlaenderen\n",
      "108 = Ghebeden onder het H. sacrificie der misse\n",
      "109 = Generaele kronycke van Vlaenderen\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('stcv.sqlite')\n",
    "c = conn.cursor()\n",
    "query = \"select distinct title_ti from title\"\"\"\n",
    "c.execute(query)\n",
    "BOOK_TITLES = []\n",
    "for title in c.fetchall():\n",
    "    # *title = unpacking the tuple\n",
    "    BOOK_TITLES.append(*title)\n",
    "print(len(BOOK_TITLES), \"titles\")\n",
    "for number, result in enumerate(BOOK_TITLES[100:110]):\n",
    "    print(number + 100, '=', result)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's consider the difference between searching for the word `English` with and without an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English books to be sold by auction Catalogue d'une tres-belle collection de livres en tous genres et langages [...] dont la vente se fera en argent de change, jeudi 18 Frimaire an 11, 9 decembre 1802, et jours suivans, chez Jacques Laureys au Marché aux herbes à Malines\n",
      "A new pocket dictionary and vocabulary of the Flemish, English and French languages\n",
      "A daily exercise, and devotions, for the young ladies, and gentlewomen pensioners at the monastery of the English canonesses regulars of the holy order of S. Augustin at Bruges\n",
      "A brieff apologie, or defence of the catholike ecclesiastical hierarchie, & subordination in England, erected these later yeares by our holy father pope Clement the eyght; and impugned by certayne libels printed & published of late both in Latyn & English\n",
      "An appendix to the Apologie, lately set forth, for defence of the hierarchie, and subordination of the English catholike church, impugned by certaine discontented priestes\n",
      "A relation of the solemnetie wherewith the catholike princes K. Phillip the III. and quene Margaret were receyed in the English colledge of Valladolid the 22. of August. 1600\n",
      "A restitvtion of decayed intelligence: in antiquities. Concerning the most noble and renovvmed English nation\n",
      "Dottrina del ben morire. English\n",
      "Oratio Petri Frarini quod male reformandae religionis nomine arma sumpserunt sectarii nostri temporis habita. English\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def make_word_index(corpus):\n",
    "    index = {}\n",
    "    for title in corpus:\n",
    "        words = title.split(' ')\n",
    "        for word in words:\n",
    "            index.setdefault(word, [])\n",
    "            index[word].append(title)\n",
    "    return index\n",
    "\n",
    "def search(search_string, index):\n",
    "    # Note: global scoping can be dangerous!\n",
    "    # Perhaps there are cleaner solutions than this?\n",
    "    global BOOK_TITLES\n",
    "    global BOOK_TITLES_INDEX\n",
    "    if index:\n",
    "        return BOOK_TITLES_INDEX[search_string]\n",
    "    else:\n",
    "        result = []\n",
    "        for title in BOOK_TITLES:\n",
    "            words = title.split(' ')\n",
    "            if search_string in words:\n",
    "                result.append(title)\n",
    "        return result\n",
    "\n",
    "BOOK_TITLES_INDEX = make_word_index(BOOK_TITLES)\n",
    "result_no_index = search(\"English\", False)\n",
    "result_index = search(\"English\", True)\n",
    "for item in result_index:\n",
    "    print(item)\n",
    "print(result_no_index == result_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, the results of searching with and without a word index are the same. But what about the efficiency of the search? For this we can use Jupyter's handy feature `%timeit`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.5 ms ± 3.21 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "109 ns ± 3.34 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit search(\"English\", False)\n",
    "%timeit search(\"English\", True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference is as large as microseconds versus nanoseconds! Remember, with STCV we are only search about 26,000 titles, but consider searching a collection like the Library of Congress, which holds over 170 million items... \n",
    "\n",
    "And of course, our example was only a simple one where we built an index that allowed to connect a word with a title. Real-world applications will often build several indices, cross-indices, include variant forms and allow for all kinds of complex searches such as searching with Boolean operators, proximity search, etcetera.\n",
    "\n",
    "For instance, titles like \"The Art of Computer Programming\" and \"Zen and the Art of Motorcycle Maintanance\" could be turned into an AND-index like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"the\": {\n",
      "        \"art\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"of\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"computer\": \"The Art of Computer Programming\",\n",
      "        \"programming\": \"The Art of Computer Programming\",\n",
      "        \"zen\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"and\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"motorcycle\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"maintanance\": \"Zen and the Art of Motorcycle Maintanance\"\n",
      "    },\n",
      "    \"art\": {\n",
      "        \"the\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"of\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"computer\": \"The Art of Computer Programming\",\n",
      "        \"programming\": \"The Art of Computer Programming\",\n",
      "        \"zen\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"and\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"motorcycle\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"maintanance\": \"Zen and the Art of Motorcycle Maintanance\"\n",
      "    },\n",
      "    \"of\": {\n",
      "        \"the\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"art\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"computer\": \"The Art of Computer Programming\",\n",
      "        \"programming\": \"The Art of Computer Programming\",\n",
      "        \"zen\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"and\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"motorcycle\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"maintanance\": \"Zen and the Art of Motorcycle Maintanance\"\n",
      "    },\n",
      "    \"computer\": {\n",
      "        \"the\": \"The Art of Computer Programming\",\n",
      "        \"art\": \"The Art of Computer Programming\",\n",
      "        \"of\": \"The Art of Computer Programming\",\n",
      "        \"programming\": \"The Art of Computer Programming\"\n",
      "    },\n",
      "    \"programming\": {\n",
      "        \"the\": \"The Art of Computer Programming\",\n",
      "        \"art\": \"The Art of Computer Programming\",\n",
      "        \"of\": \"The Art of Computer Programming\",\n",
      "        \"computer\": \"The Art of Computer Programming\"\n",
      "    },\n",
      "    \"zen\": {\n",
      "        \"and\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"the\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"art\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"of\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"motorcycle\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"maintanance\": \"Zen and the Art of Motorcycle Maintanance\"\n",
      "    },\n",
      "    \"and\": {\n",
      "        \"zen\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"the\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"art\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"of\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"motorcycle\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"maintanance\": \"Zen and the Art of Motorcycle Maintanance\"\n",
      "    },\n",
      "    \"motorcycle\": {\n",
      "        \"zen\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"and\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"the\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"art\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"of\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"maintanance\": \"Zen and the Art of Motorcycle Maintanance\"\n",
      "    },\n",
      "    \"maintanance\": {\n",
      "        \"zen\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"and\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"the\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"art\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"of\": \"Zen and the Art of Motorcycle Maintanance\",\n",
      "        \"motorcycle\": \"Zen and the Art of Motorcycle Maintanance\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from json import dumps\n",
    "titles = [\"The Art of Computer Programming\", \"Zen and the Art of Motorcycle Maintanance\"]\n",
    "AND_INDEX = {}\n",
    "for title in titles:\n",
    "    clean_title = title.casefold()\n",
    "    for word in clean_title.split(' '):\n",
    "        if not word in AND_INDEX:\n",
    "            AND_INDEX[word] = {}\n",
    "        for next_word in clean_title.split(' '):\n",
    "            if not word == next_word:\n",
    "                AND_INDEX[word].update({next_word: title})\n",
    "print(dumps(AND_INDEX, indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way, searching with `AND` becomes easy in this index, e.g. books that combine \"art\" and \"computer\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Art of Computer Programming\n"
     ]
    }
   ],
   "source": [
    "print(AND_INDEX[\"art\"][\"computer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excursus: Bitmap indexing\n",
    "\n",
    "A lot more can be said about indexing. For one, you might wonder if indexing in itself might not lead to building overly large data structures that take up a lot of space and memory. As was clear from the above example of a combined index, indexing can quickly escalate.\n",
    "\n",
    "One interesting technique to avoid such problems is bitmap indexing. [Wikipedia](https://en.wikipedia.org/wiki/Bitmap) says:\n",
    "\n",
    "> In computing, a bitmap is a mapping from some domain (for example, a range of integers) to bits\n",
    "\n",
    "Let's say you are a button factory and have produced 10,000,000 buttons of a certain type. Now you want to keep track of which buttons have been sold by recording their serial numbers. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 bytes\n"
     ]
    }
   ],
   "source": [
    "from sys import getsizeof\n",
    "import array\n",
    "\n",
    "# using arrays which is more memory-efficient than lists\n",
    "# https://docs.python.org/3/library/array.html\n",
    "pens_sold = array.array('B', [1, 5, 10])\n",
    "print(getsizeof(pens_sold), 'bytes')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you need 67 bytes to store this information as a Python array. By the time all buttons have been sold the list will be this large:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.29399900576193 megabytes\n"
     ]
    }
   ],
   "source": [
    "all_pens_sold = array.array('L', [i for i in range(1,10000000)])\n",
    "size = getsizeof(all_pens_sold) * 0.00000095367432\n",
    "print(size, 'megabytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "So you see, things can get out of hand quickly. But if you use a bitmapping system, things are radically different:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 bytes\n",
      "9.536803281482161 megabytes\n"
     ]
    }
   ],
   "source": [
    "# setting a bit array here with array (https://docs.python.org/3/library/array.html)\n",
    "# in real applications you should use https://pypi.org/project/bitmap/\n",
    "\n",
    "import array\n",
    "\n",
    "# a bit array of unsigned ints with bits 1, 5 and 10 set to 1 (= pens sold)\n",
    "pens_sold = array.array('B', [0b1, 0b0, 0b0, 0b0, 0b1, 0b0, 0b0, 0b0, 0b0, 0b1])\n",
    "print(getsizeof(pens_sold), 'bytes')\n",
    "\n",
    "bitmap_of_all_pens_sold = array.array('B', [0b1 for i in range(1,10000000)])\n",
    "size = getsizeof(bitmap_of_all_pens_sold) * 0.00000095367432\n",
    "print(size, 'megabytes')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lucene\n",
    "\n",
    "The leading software for indexing and searching text is definitely [Lucene](https://lucene.apache.org/). However, Lucene is a Java library, which is not easy to implement (especially crossplatform as would be the case in this course). \n",
    "\n",
    "There is a Python extension for accessing Java Lucene, called [PyLucene](https://lucene.apache.org/pylucene/). Its goal is to allow you to use Lucene's text indexing and searching capabilities from Python. Still, PyLucene is not a Lucene **port** but a Python **wrapper** around Java Lucene. PyLucene embeds a Java VM with Lucene into a Python process. This means that you still need Java Lucene to run PyLucene, and some additional tools (GNU `Make`, a C++ compiler, etc.).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whoosh\n",
    "\n",
    "As text indexing/searching is bound to be really slow in Python (so it make good sense to stick to Java Lucene) there is no true pure-Python alternative to Lucene. However, there are some libraries that allow you to experiment with similar indexing/searching software.\n",
    "\n",
    "One of these is [Whoosh](https://whoosh.readthedocs.io/en/latest/index.html), which is unfortunately no longer maintained. Still, the latest version, 2.7.4, still works fine for Python 3 and can easily be installed through `pip install Whoosh`.\n",
    "\n",
    "In the [Whoosh introduction](https://whoosh.readthedocs.io/en/latest/intro.html) we read:\n",
    "\n",
    "> **About Whoosh**\n",
    ">- Whoosh is fast, but uses only pure Python, so it will run anywhere Python runs, without requiring a compiler.\n",
    ">- By default, Whoosh uses the Okapi BM25F ranking function, but like most things the ranking function can be easily customized.\n",
    ">- Whoosh creates fairly small indexes compared to many other search libraries.\n",
    ">- All indexed text in Whoosh must be unicode.\n",
    ">- Whoosh lets you store arbitrary Python objects with indexed documents.\n",
    "\n",
    "> **What is Woosh**\n",
    "\n",
    ">Whoosh is a fast, pure Python search engine library.\n",
    "\n",
    ">The primary design impetus of Whoosh is that it is pure Python. You should be able to use Whoosh anywhere you can use Python, no compiler or Java required.\n",
    "\n",
    ">Like one of its ancestors, Lucene, Whoosh is not really a search engine, it’s a programmer library for creating a search engine.\n",
    "\n",
    ">Practically no important behavior of Whoosh is hard-coded. Indexing of text, the level of information stored for each term in each field, parsing of search queries, the types of queries allowed, scoring algorithms, etc. are all customizable, replaceable, and extensible.\n",
    "\n",
    "Indeed, Whoosh is quite similar to Lucene, including its query language. It lets you connect terms with `AND` or `OR`, eleminate terms with `NOT`, group terms together into clauses with parentheses, do range, prefix, and wilcard queries, and specify different fields to search. By default it joins clauses together with `AND` (so by default, all terms you specify must be in the document for the document to match)\n",
    "\n",
    "The following code shows you how to create and search a basic Whoosh index. For more information, see the [Whoosh quick start](https://whoosh.readthedocs.io/en/latest/quickstart.html) and documentation on the [query language](https://whoosh.readthedocs.io/en/latest/querylang.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and customs,\n",
      "\n",
      "\tand a <b class=\"match term0\">smattering</b> of the language...that he had no <b class=\"match term0\">smattering</b> of\n",
      "\n",
      "\tchemistry...of tune. She had a <b class=\"match term0\">smattering</b> of half-\n",
      "\n",
      "\ta-dozen...to me;\n",
      "\n",
      "\tfor I had a <b class=\"match term0\">smattering</b> of French--and\n",
      "and politics, hath a\n",
      "\n",
      "\t<b class=\"match term0\">smattering</b> in law and divinity...I have\n",
      "\n",
      "\ta small <b class=\"match term0\">smattering</b> in surgery,\" answered...the gentleman.--\"A\n",
      "\n",
      "\t<b class=\"match term0\">smattering</b>--ho, ho, ho!\" said...I believe it is a\n",
      "\n",
      "\t<b class=\"match term0\">smattering</b> indeed.\"\n",
      "\n",
      "\tThe company\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Whoosh quick start\n",
    "Source: https://whoosh.readthedocs.io/en/latest/quickstart.html\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "from whoosh import highlight\n",
    "from whoosh.index import open_dir, create_in\n",
    "from whoosh.fields import Schema, STORED, ID, KEYWORD, TEXT\n",
    "from whoosh.qparser import QueryParser\n",
    "from whoosh.query import *\n",
    "\n",
    "# Create schema\n",
    "\"\"\"\n",
    "To begin using Whoosh, you need an index object. The first time you create\n",
    "an index, you must define the index’s schema. The schema lists the fields in\n",
    "the index. A field is a piece of information for each document in the index,\n",
    "such as its title or text content. A field can be indexed (meaning it can be\n",
    "searched) and/or stored (meaning the value that gets indexed is returned with\n",
    "the results; this is useful for fields such as the title).\n",
    "\"\"\"\n",
    "\n",
    "schema = Schema(title=TEXT(stored=True), content=TEXT(stored=True),\n",
    "                path=ID(stored=True))\n",
    "\n",
    "# Create index\n",
    "\"\"\"\n",
    "Once you have the schema, you can create an index.\n",
    "At a low level, this creates a Storage object to contain the index.\n",
    "A Storage object represents that medium in which the index will be stored.\n",
    "Usually this will be FileStorage, which stores the index as a set of files\n",
    "in a directory.\n",
    "\"\"\"\n",
    "\n",
    "if not os.path.exists(\"index\"):\n",
    "    os.mkdir(\"index\")\n",
    "ix = create_in(\"index\", schema)\n",
    "\n",
    "# Add documents\n",
    "\"\"\"\n",
    "OK, so we’ve got an Index object, now we can start adding documents.\n",
    "The writer() method of the Index object returns an IndexWriter object that\n",
    "lets you add documents to the index. The IndexWriter’s add_document(**kwargs)\n",
    "method accepts keyword arguments where the field name is mapped to a value.\n",
    "\n",
    "The documents we add, a small corpus of British fiction, are part of\n",
    "the chapter06 repo.\n",
    "\"\"\"\n",
    "\n",
    "OS_SEP = os.sep  # take care, different OS use different filepath separators!\n",
    "\n",
    "writer = ix.writer()\n",
    "\n",
    "for document in os.listdir(\"corpus_of_british_fiction\"):\n",
    "    with open(\"corpus_of_british_fiction\" + OS_SEP + document, 'r') as text:\n",
    "        writer.add_document(title=document, content=str(text.read()),\n",
    "                            path=document)\n",
    "writer.commit()\n",
    "\n",
    "\n",
    "# Parse a query string\n",
    "\"\"\"\n",
    "Woosh's Searcher (cf.infra) takes a Query object. You can construct query\n",
    "objects directly or use a query parser to parse a query string.\n",
    "To parse a query string, you can use the default query parser in the qparser\n",
    "module. The first argument to the QueryParser constructor is the default field\n",
    "to search. This is usually the \"body text\" field. The second optional argument\n",
    "is a schema to use to understand how to parse the fields.\n",
    "\"\"\"\n",
    "myquery = QueryParser(\"content\", ix.schema).parse('smattering')\n",
    "\n",
    "# Search documents\n",
    "\"\"\"\n",
    "Once you have a Searcher and a query object, you can use the Searcher's\n",
    "search() method to run the query and get a Results object. You can use the\n",
    "highlights() method on the whoosh.searching.Hit object to get highlighted\n",
    "snippets from the document containing the search terms.\n",
    "\"\"\"\n",
    "with ix.searcher() as searcher:\n",
    "    results = searcher.search(myquery, limit=None)\n",
    "    # https://whoosh.readthedocs.io/en/latest/highlight.html#the-character-limit\n",
    "    results.fragmenter.charlimit = None\n",
    "    for hit in results:\n",
    "        print(hit.highlights(\"content\", top=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment: Morphology tool\n",
    "\n",
    "Use Whoosh to teach English morphology with examples from a given corpus. For instance, through the rules of morphology verbs can take different forms or be used to form nouns, adjectives and such, like:\n",
    "\n",
    "- `render`: 'renders', 'rendered', 'rendering'\n",
    "- `think`: 'thinks', 'thought', 'thinking', 'thinker', 'thinkers', 'thinkable'\n",
    "- `put`: 'puts', 'putting', 'putter'\n",
    "- `do`: 'does', 'did', 'done', 'doing', 'doings', 'doer', 'doers'\n",
    "\n",
    "Forms like `put` and `do` illustrate that you cannot approach this problem in a mechanical or brute-force way. It is not as simple as adding 'ed', 'ing', etcetera to the verbs. Sometimes consonants are doubled, sometimes the verb stem changes (in the case of strong verbs), and so on.\n",
    "\n",
    "Whoosh has a particular feature to deal with this. Use it to build a Python application that takes a word as input and returns a list of sentences from the British fiction corpus (folder `corpus_of_british_fiction` in this repo) that contain this word to illustrate its usage. Think about building the index first, so you can then reuse it (without having to rebuild it) for additional searches.\n",
    "\n",
    "Also, try to display the results nicely, i.e. without the markup tags we saw in the above example. Maybe you can even print the matched word in bold?\n",
    "\n",
    "If this is an easy task for you, try to convert this approach to look for examples of phrasal verbs, i.e. \"to put off\" (variant forms 'put off', 'puts off', 'putting off', etcetera)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   },
   "name": "Python 3.8.2 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}