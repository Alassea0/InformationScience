{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: Encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/Hello_World_Brainfuck.png)\n",
    "\n",
    "\"Hello world\" program in __[Brainfuck](https://en.wikipedia.org/wiki/Brainfuck)__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *TL;DR: There is no such thing as pure information. Information is encoded and needs to be decoded and manipulated before use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating Information\n",
    "\n",
    "Let's go back to Paul Otlet and his index cards for a minute. For me, one of the key takeaways of this story is the simple fact that information never just *is*. Even when we thing we are merely making it accessable through catalogs or search engines, information is, as postmodern philosopher [Jacques Derrida](https://en.wikipedia.org/wiki/Jacques_Derrida) would say, *always already* manipulated. \n",
    "\n",
    "So we could say that at the heart of information retrieval is **manipulating information**, i.e. selecting, grouping, filtering, ordering, sorting, ranking. In fact, `select`, `group`, `filter`, `order`, `sort` and `rank` are arguably the most important keywords in the world's most used database query language, [SQL](https://en.wikipedia.org/wiki/SQL), which we will talk about later.\n",
    "\n",
    "In programming terms, this manipulation often boils down to basic **string operations**, like testing metadata for certain criteria or sorting them. And while manipulating strings might seem easy, things can get complicated really easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting strings\n",
    "\n",
    "Let's look at the example of sorting strings. Suppose our task is presenting an alphabetized list of contact persons. \n",
    "\n",
    "Of course, in Python you can just do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Doe, Jane', 'Doe, John', 'Poppins, Mary']\n"
     ]
    }
   ],
   "source": [
    "contacts = [\"Doe, John\", \"Poppins, Mary\", \"Doe, Jane\"]\n",
    "sorted_contacts = sorted(contacts)\n",
    "print(sorted_contacts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But suppose you are dealing with a programming language where there is no built-in sorting method. (And believe me, there are!) How would you go about sorting a list of strings?\n",
    "\n",
    "The key to this problem is that in computing there really is no such thing as characters. All characters are represented by some numerical value and various sorting algorithms use these values to implement string sorting. \n",
    "\n",
    "This takes us to the issue of encoding, which is at the heart of all things digital."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding\n",
    "\n",
    "Encoding is not an easy concept to wrap your head around. When I first started out programming, I took me quite some time to really grasp it. \n",
    "\n",
    "So let's see if we can come to understand it with this Medium blogpost called [Text versus bytes](https://medium.com/analytics-vidhya/dev-101-text-versus-bytes-70548216409b), which I wrote especially for beginners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unicode\n",
    "\n",
    "Now that we have a better understanding of encoding, let's go back to our sorting example, and consider the application of [Unicode](https://en.wikipedia.org/wiki/Unicode) code points for mapping characters to numerical values. In Python we can use the function `ord()` to get a character's decimal Unicode code point:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68,111,101,44,32,74,111,104,110,"
     ]
    }
   ],
   "source": [
    "for char in \"Doe, John\":\n",
    "    print(ord(char), end=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good, it seems. But matters quickly get complex. One example is the difference between upper and lower case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100,111,101,44,32,106,111,104,110,\n",
      "\n",
      "68,79,69,44,32,74,79,72,78,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in [\"doe, john\", \"DOE, JOHN\"]:\n",
    "    for char in item:\n",
    "        print(ord(char),end=\",\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can account for that by converting all strings to lower case before sorting, but what happens in the case of the French `Étienne` versus `Etienne`, which you would want to be sorted close to each other and are, in fact, used interchangeably?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é = 233\n",
      "t = 116\n",
      "i = 105\n",
      "e = 101\n",
      "n = 110\n",
      "n = 110\n",
      "e = 101\n",
      "\n",
      "\n",
      "e = 101\n",
      "t = 116\n",
      "i = 105\n",
      "e = 101\n",
      "n = 110\n",
      "n = 110\n",
      "e = 101\n"
     ]
    }
   ],
   "source": [
    "for char in \"Étienne\".lower():\n",
    "    print(char + \" = \" + str(ord(char)))\n",
    "print(\"\\n\")\n",
    "for char in \"Etienne\".lower():\n",
    "    print(char + \" = \" + str(ord(char)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can complicate matters even more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Å\n",
      "Å\n",
      "Å\n"
     ]
    }
   ],
   "source": [
    "print('\\u00C5')\n",
    "print('\\u212B')\n",
    "print('\\u0041\\u030A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows that even Unicode code points don't offer a unique mapping of characters to numbers. To solve this, there is luckily something called [Unicode normalization](https://en.wikipedia.org/wiki/Unicode_equivalence#Normalization)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding\n",
    "\n",
    "It is important to realize that all text-oriented interfaces that you use to display text will make implicit or explicit assumptions about the encoding of texts. Whether it is your terminal environment, the editor you use (e.g. VSCode) or even a programming language, you need to be aware of such default encodings.\n",
    "\n",
    "For instance, Python3 (not Python2) is default UTF8. So if you receive strings in a different encoding, which will happen in real-life applications like scraping text from the internet, you'll have to decode them with the proper codec to render your results properly.\n",
    "\n",
    "Let's simulate what would happen if you were working with non-UTF8 encoded strings in Python3 and decode them with the default codec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xc3\\xa9'\n",
      "é\n",
      "b'\\xe9'\n",
      "Unable to print bytes b'\\xe9' in UTF8\n",
      "b'\\x82'\n",
      "Unable to print bytes b'\\x82' in UTF8\n"
     ]
    }
   ],
   "source": [
    "e_accent_aigue = chr(233)  # unicode code point for é character\n",
    "for encoding in ['utf8', 'latin1', 'ibm850']:\n",
    "    bytes_string = e_accent_aigue.encode(encoding=encoding)\n",
    "    print(bytes_string)\n",
    "    try:\n",
    "        print(bytes_string.decode())  # this is equal to .decode(encoding='utf8')\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Unable to print bytes {bytes_string} in UTF8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see how complex seemingly trivial tasks of information theory, like alphabetizing a list,really are. We've gone from Paul Otlet's grand visions of the future to the nitty-gritty bits and bytes, one of the most fundamental concepts in computer science, really quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment: Onegram Counter\n",
    "\n",
    "You probably know about Google Book's __[Ngram Viewer](https://books.google.com/ngrams)__: when you enter phrases into it, it displays a graph showing how those phrases have occurred in a corpus of books (e.g., \"British English\", \"English Fiction\", \"French\") over the selected years. \n",
    "\n",
    "Your assignment for this course is something similar: build a Python function that can take the file `data/corpus.txt` (UTF-8 encoded) from this repo as an argument and print a count of the 100 most frequent 1-grams (i.e. single words).\n",
    "\n",
    "In essence the job is to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 11852), ('', 5952), ('of', 5768), ('and', 5264), ('to', 4027), ('a', 3980), ('in', 3548), ('that', 2336), ('his', 2061), ('it', 1517), ('as', 1490), ('i', 1488), ('with', 1460), ('he', 1448), ('is', 1400), ('was', 1393), ('for', 1337), ('but', 1319), ('all', 1148), ('at', 1116), ('this', 1063), ('by', 1042), ('from', 944), ('not', 933), ('be', 863), ('on', 850), ('so', 763), ('you', 718), ('one', 694), ('have', 658), ('had', 647), ('or', 638), ('were', 551), ('they', 547), ('are', 504), ('some', 498), ('my', 484), ('him', 480), ('which', 478), ('their', 478), ('upon', 475), ('an', 473), ('like', 470), ('when', 458), ('whale', 456), ('into', 452), ('now', 437), ('there', 415), ('no', 414), ('what', 413), ('if', 404), ('out', 397), ('up', 380), ('we', 379), ('old', 365), ('would', 350), ('more', 348), ('been', 338), ('over', 324), ('only', 322), ('then', 312), ('its', 307), ('such', 307), ('me', 307), ('other', 301), ('will', 300), ('these', 299), ('down', 270), ('any', 269), ('than', 262), ('has', 257), ('very', 252), ('though', 245), ('yet', 245), ('those', 242), ('must', 238), ('them', 237), ('her', 237), ('do', 234), ('about', 234), ('said', 233), ('ye', 232), ('who', 231), ('still', 229), ('great', 229), ('most', 228), ('man', 220), ('two', 219), ('seemed', 216), ('long', 214), ('your', 213), ('before', 212), ('it,', 210), ('thou', 210), ('ship', 209), ('after', 208), ('white', 207), ('did', 202), ('little', 201), ('him,', 194)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "def onegrams(file):\n",
    "    with open(file, 'r') as corpus:\n",
    "        text = corpus.read()\n",
    "        # .casefold() is better than .lower() here\n",
    "        # https://www.programiz.com/python-programming/methods/string/casefold\n",
    "        normalize = text.casefold()\n",
    "        words = normalize.split(' ')\n",
    "        count = Counter(words) \n",
    "        return count\n",
    "\n",
    "ngram_viewer = onegrams(os.path.join('data', 'corpus.txt'))\n",
    "print(ngram_viewer.most_common(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there is a twist: you can't use the `collections` library...\n",
    "\n",
    "Moreover, try to think about what may be suboptimal in this example. For instance, in this code all of the text is loaded into memory in one time (with the `read()` method). What would happen if we tried this on a really big text file? \n",
    "\n",
    "**Most importantly, the count is also wrong**. Check by counting in an editor, for instance, and try to find out why.\n",
    "\n",
    "If this is an easy task for you, you can also think about the graphical representation of the 1-gram count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading\n",
    "\n",
    "- If you want to get a really good idea of how complex counting words can get, you can read this blog post __[Performance comparison: counting words in Python, Go, C++, C, AWK, Forth, and Rust](https://benhoyt.com/writings/count-words/)__."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
